{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATS 507 HW8 MapReduce, Hadoop and Spark\n",
    "#### Meng-Ni Ho\n",
    "#### mandyho@umich.edu\n",
    "\n",
    "Problem 1: 1hr, Problem 2: 3hr, Problem 3: 4hr  \n",
    "Went to office hours for part 2 and part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 Warmup: counting words with mrjob (3 points)\n",
    "In this problem, you’ll get a gentle introduction to mrjob and running mrjob on the Fladoop cluster. I have uploaded a large text file to the Fladoop cluster. Your job is to count how many times each word occurs in this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write an mrjob job that takes text as input and counts how many times each word occurs in the text. \n",
    "\n",
    "   * Your script should strip punctuation like full stops, commas and semicolons, but you may treat hyphens, apostrophes, etc. as you wish. Simplest is to treat, e.g., “John’s” as two words, “John” and “s”, but feel free to do more complicated processing if you wish.   \n",
    "   * Your script should ignore case, so that “Cat” and “cat” are considered the same word. \n",
    "   * Your output should be a collection of (word,count) pairs. \n",
    "   * Please save your script in a file called __mr_word_count.py__ and include it in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRWordCount(MRJob):\n",
    "\t\n",
    "\t# Mapper: read each word as key, set value = 1\n",
    "\tdef mapper(self, _, line):\n",
    "\t\tfor word in WORD_RE.findall(line):\n",
    "\t\t\tyield word.lower(), 1\n",
    "\t\n",
    "\t# reducer: count frequency for each word\n",
    "\tdef reducer(self, key, value):\n",
    "\t\tyield key, sum(value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordCount.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. To test your code, I have uploaded a simple text file to the course webpage:\n",
    "http://www-personal.umich.edu/~klevin/teaching/Winter2019/STATS507/simple.txt .\n",
    "   * Download this file and test your code either on your local machine or on the Fladoop grid. The file is small enough that you should be able to check by hand whether your code is behaving correctly.   \n",
    "   * Save the output of running your script on this small file to a file called __simple_word_counts.txt__ and include it in your submission. \n",
    "   * Note: use the redirect arrow > to send the Hadoop output to a file. This will only send the stdout output to the file, while still printing the Hadoop error/status messages to the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __simple.txt__ is modified to test punctuations and numbers\n",
    "* hyphened words will be split up, apostrophes will not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command lime for submitting mrjob on local machine:  \n",
    "`python3 mr_word_count.py simple.txt > simple_word_counts.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Once you are confident in the correctness of your program, run your mrjob script on the file \n",
    "                            hdfs:///var/stat507w19/darwin.txt   \n",
    "on the Fladoop grid (this file is the Project Gutenberg plain text version of Charles Darwin’s scientific work On the Origin of Species). \n",
    "  * Note that this file is on hdfs, not the local file system, so you’ll have to run your script accordingly.  \n",
    "  * Save the output to a file called __darwin_word_counts.txt__, and include it in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command line for submiting mrjob:  \n",
    "1. on local machine: upload script to grid  \n",
    "`scp mr_word_count.py mandyho@flux-hadoop-login.arc-ts.umich.edu:~/hadoop/mr_word_count.py`  \n",
    "2. on hadoop:   \n",
    "`python mr_word_count.py -r hadoop hdfs:///var/stats507w19/darwin.txt > darwin_word_counts.txt`  \n",
    "3. on local machine: download result txt to local machine  \n",
    "`scp mandyho@flux-hadoop-login.arc-ts.umich.edu:~/hadoop/darwin_word_counts.txt .` \n",
    "('.' indicate any place on the directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Zipf’s law states, roughly, that if one plots word frequency against frequency rank (i.e., most frequent word, second most frequent word, etc.), the resulting line is (approximately) linear on a log-log scale. \n",
    "   * Using the information in __darwin_word_counts.txt__, make a plot of word frequency (y-axis) as a function of word rank (x-axis) on a _log-log scale_ for all words in the file\n",
    "                   hdfs:///var/stats507w19/darwin.txt\n",
    "   * Give an appropriate title to your plot and include axis labels. \n",
    "   * Save the plot as a pdf file called __zipf.pdf__, and include it in your submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14734, 10543, 5919, 5471, 4832, 3437, 2764, 2240, 2119, 2118]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract word counts\n",
    "freq_list = []\n",
    "with open(\"darwin_word_counts.txt\", \"r\") as f:\n",
    "    for l in f.readlines():\n",
    "        word, freq = l.split()\n",
    "        freq_list.append(int(freq))\n",
    "freq_list.sort(reverse=True)\n",
    "freq_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create rank list\n",
    "rank = [x+1 for x in range(len(freq_list))]\n",
    "rank[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure()\n",
    "plt.scatter(rank,freq_list)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.title(\"The Zipf's law of Darwin text\")\n",
    "plt.xlabel(\"Word Rank (log-scale)\")\n",
    "plt.ylabel(\"Word Frequency (log-scale)\")\n",
    "f.savefig('zipf.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. How “Zipfian” does the resulting plot look (It suffices for you to state whether or not your plot looks approximately like a line)? \n",
    "\n",
    "You can read more about Zipf’s law and about power laws generally at the respective Wikipedia pages (https://en.wikipedia.org/wiki/Zipf’s_law , https://en.wikipedia.org/wiki/Power_law). For more about power laws, I recommend this survey paper by Mark Newman, a faculty member here at University of Michigan https://arxiv.org/pdf/cond-mat/0412004.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship between rank and frequency is linear under log-log scale, with a negative slope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Computing Sample Statistics with mrjob (6 points)\n",
    "In this problem, we’ll compile some very basic statistics summarizing a toy dataset. The file\n",
    "http://www-personal.umich.edu/~klevin/teaching/Winter2019/STATS507/populations_small.txt\n",
    "contains a collection of (class,value) pairs, one per line, with each line taking the form class label,value, where class label is a nonnegative integer and value is a float. Each pair corresponds to an observation, with the class labels corresponding to different populations, and the values corresponding to some measured quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write a mrjob program called mr_summary_stats.py that \n",
    "   * takes as input a sequence of (label,value) pairs like in the file at http://www-personal.umich.edu/~klevin/teaching/Winter2019/STATS507/populations_small.txt, and \n",
    "   * outputs a collection of __(label, number of samples, mean, variance)__ 4-tuples, in which one 4-tuple appears for each class label in the data, and the mean and variance are the sample mean and variance, respectively, of all the values for that class label. \n",
    "   * Thus, if 25 unique class labels are present in the input then your program should output 25 lines, one for each class label. \n",
    "   * __Note__: I don’t care whether you use n or n − 1 in the denominator of your sample variance formula—just be clear which one you are using. \n",
    "   * __Note__: you don’t need to do any special formatting of the Hadoop output. That is, your output is fine if it consists of lines of the form `label [number,mean,variance]` or similar.\n",
    "   * Think carefully about what your key-value pairs should be here, as well as what your mappers, reducers, etc. should be. Should there be more than one step in your job? Sit down with pen and paper first! \n",
    "   * __Hint__: to compute the sample mean and sample variance of a collection of numbers, it suffices to know their sum, the sum of their squares, and the size of the collection.\n",
    "   * Please include a copy of __mr_summary_stats.py__ in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# mr_summary_stats.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from functools import reduce\n",
    "import sys\n",
    "\n",
    "\n",
    "class MRSummaryStatistics(MRJob):\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper = self.mapper_get_label_value,\n",
    "                   reducer = self.reducer_summation),\n",
    "            MRStep(reducer = self.reducer_statistic)\n",
    "        ]\n",
    "\n",
    "    # Two reduce steps: first compute summation, then statistics\n",
    "    \n",
    "    def mapper_get_label_value(self, _, line):\n",
    "        each_line = line.split()\n",
    "        # if elements after split is not equal to 2, exit\n",
    "        if len(each_line) != 2:\n",
    "            print(line)\n",
    "            sys.exit(1)\n",
    "        label = int(each_line[0])\n",
    "        values = float(each_line[1])\n",
    "        yield label, values\n",
    "\n",
    "    def reducer_summation(self, label, values):\n",
    "        # input: key = label, value\n",
    "        # output: key = label, value (3-tuple: number of sample, sum of value, sum of square of value)\n",
    "        # n = a[0]+1\n",
    "        # sum = a[1]+b\n",
    "        # sum of square = a[2]+b\n",
    "        yield (label, reduce(lambda a, b: (a[0]+1, a[1]+b, a[2]+b**2), values, (0.0,0.0,0.0)))\n",
    "\n",
    "    def reducer_statistic(self, label, values):\n",
    "        # input: key = label, value (3-tuple: number of sample, sum of value, sum of square of value)\n",
    "        # output: 4-tuple(label, n, mean, variance)\n",
    "        # mean = sum/n\n",
    "        # variance = sum of square/n - (sum/n)**2\n",
    "        yield (label, reduce(lambda a,b: (b[0], b[1]/b[0], b[2]/b[0]-(b[1]/b[0])**2), values, (0,0,0)))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRSummaryStatistics.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Download the small file at http://www-personal.umich.edu/~klevin/teaching/Winter2019/STATS507/populations_small.txt. \n",
    "   * Run your mrjob script on this file, either on your local machine or on Fladoop, and write the output to a file called __summary_small.txt__. \n",
    "   * Please include this file in your submission. \n",
    "   * Inspect your program’s output and verify that it is behaving as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command line on local machine:  \n",
    "`python3 mr_summary_stats.py populations_small.txt > summary_small.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. I have uploaded to the Fladoop cluster a much larger data file, located on the HDFS file system at \n",
    "                    hdfs:///var/stats507w19/populations_large.txt. \n",
    "Once you are sure that your script is doing what you want, run it on this file. \n",
    "   * Be sure to use the `-r hadoop` command to tell mrjob to run on the Hadoop server rather than on the login node.\n",
    "   * Save the output to a file called __summary_large.txt__. \n",
    "   * Download this file and include it in your submission. \n",
    "   * Please also include in your notebook file a copy-paste of your shell session on Fladoop in a markdown cell (i.e., a cell that will display as code but will not be executed by the interpreter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line:  \n",
    "1. on local machine: upload script to grid   \n",
    "`scp mr_summary_stats.py mandyho@flux-hadoop-login.arc-ts.umich.edu:~/hadoop/mr_summary_stats.py`\n",
    "2. Run job on Fladoop:  \n",
    "`python mr_summary_stats.py -r hadoop hdfs:///var/stats507w19/populations_large.txt > summary_large.txt`  \n",
    "3. Download result txt on local machine:  \n",
    "`scp mandyho@flux-hadoop-login.arc-ts.umich.edu:~/hadoop/summary_large.txt .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shell Session from Fladoop:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[mandyho@flux-hadoop-login2 hadoop]$ python mr_summary_stats.py -r hadoop hdfs:///var/stats507w19/populations_large.txt > summary_large.txt\n",
    "Using configs in /etc/mrjob.conf\n",
    "Looking for hadoop binary in $PATH...\n",
    "Found hadoop binary: /usr/bin/hadoop\n",
    "Using Hadoop version 2.7.3.2.6.3.0\n",
    "Looking for Hadoop streaming jar in /home/hadoop/contrib...\n",
    "Looking for Hadoop streaming jar in /usr/lib/hadoop-mapreduce...\n",
    "Found Hadoop streaming jar: /usr/lib/hadoop-mapreduce/hadoop-streaming.jar\n",
    "Creating temp directory /tmp/mr_summary_stats.mandyho.20190403.233005.326941\n",
    "Copying local files to hdfs:///user/mandyho/tmp/mrjob/mr_summary_stats.mandyho.20190403.233005.326941/files/...\n",
    "Running step 1 of 2...\n",
    "  packageJobJar: [] [/usr/hdp/2.6.3.0-235/hadoop-mapreduce/hadoop-streaming-2.7.3.2.6.3.0-235.jar] /tmp/streamjob4306968943705422671.jar tmpDir=null\n",
    "  Connecting to ResourceManager at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:8050\n",
    "  Connecting to Application History server at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:10200\n",
    "  Connecting to ResourceManager at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:8050\n",
    "  Connecting to Application History server at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:10200\n",
    "  Created HDFS_DELEGATION_TOKEN token 135025 for mandyho on 10.164.5.158:8020\n",
    "  Got dt for hdfs://fladoop-nn02.arc-ts.umich.edu:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 10.164.5.158:8020, Ident: (HDFS_DELEGATION_TOKEN token 135025 for mandyho)\n",
    "  Total input paths to process : 1\n",
    "  Adding a new node: /default-rack/10.164.1.143:1019\n",
    "  Adding a new node: /default-rack/10.164.1.140:1019\n",
    "  Adding a new node: /default-rack/10.164.1.144:1019\n",
    "  Adding a new node: /default-rack/10.164.1.141:1019\n",
    "  Adding a new node: /default-rack/10.164.1.142:1019\n",
    "  Adding a new node: /default-rack/10.164.1.145:1019\n",
    "  number of splits:2\n",
    "  Submitting tokens for job: job_1547074859606_12269\n",
    "  Kind: HDFS_DELEGATION_TOKEN, Service: 10.164.5.158:8020, Ident: (HDFS_DELEGATION_TOKEN token 135025 for mandyho)\n",
    "  Timeline service address: http://fladoop-rm01.arc-ts.umich.edu:8188/ws/v1/timeline/\n",
    "  Submitted application application_1547074859606_12269\n",
    "  The url to track the job: http://fladoop-rm01.arc-ts.umich.edu:8088/proxy/application_1547074859606_12269/\n",
    "  Running job: job_1547074859606_12269\n",
    "  Job job_1547074859606_12269 running in uber mode : false\n",
    "   map 0% reduce 0%\n",
    "   map 8% reduce 0%\n",
    "   map 13% reduce 0%\n",
    "   map 19% reduce 0%\n",
    "   map 24% reduce 0%\n",
    "   map 30% reduce 0%\n",
    "   map 35% reduce 0%\n",
    "   map 41% reduce 0%\n",
    "   map 46% reduce 0%\n",
    "   map 52% reduce 0%\n",
    "   map 57% reduce 0%\n",
    "   map 63% reduce 0%\n",
    "   map 67% reduce 0%\n",
    "   map 83% reduce 0%\n",
    "   map 100% reduce 0%\n",
    "   map 100% reduce 57%\n",
    "   map 100% reduce 67%\n",
    "   map 100% reduce 71%\n",
    "   map 100% reduce 75%\n",
    "   map 100% reduce 78%\n",
    "   map 100% reduce 83%\n",
    "   map 100% reduce 85%\n",
    "   map 100% reduce 89%\n",
    "   map 100% reduce 93%\n",
    "   map 100% reduce 94%\n",
    "   map 100% reduce 100%\n",
    "  Job job_1547074859606_12269 completed successfully\n",
    "  Output directory: hdfs:///user/mandyho/tmp/mrjob/mr_summary_stats.mandyho.20190403.233005.326941/step-output/0000\n",
    "Counters: 50\n",
    "\tFile Input Format Counters \n",
    "\t\tBytes Read=153028684\n",
    "\tFile Output Format Counters \n",
    "\t\tBytes Written=1386\n",
    "\tFile System Counters\n",
    "\t\tFILE: Number of bytes read=171854192\n",
    "\t\tFILE: Number of bytes written=344192148\n",
    "\t\tFILE: Number of large read operations=0\n",
    "\t\tFILE: Number of read operations=0\n",
    "\t\tFILE: Number of write operations=0\n",
    "\t\tHDFS: Number of bytes read=153028946\n",
    "\t\tHDFS: Number of bytes written=1386\n",
    "\t\tHDFS: Number of large read operations=0\n",
    "\t\tHDFS: Number of read operations=9\n",
    "\t\tHDFS: Number of write operations=2\n",
    "\tJob Counters \n",
    "\t\tData-local map tasks=1\n",
    "\t\tLaunched map tasks=2\n",
    "\t\tLaunched reduce tasks=1\n",
    "\t\tRack-local map tasks=1\n",
    "\t\tTotal megabyte-milliseconds taken by all map tasks=191203328\n",
    "\t\tTotal megabyte-milliseconds taken by all reduce tasks=162807808\n",
    "\t\tTotal time spent by all map tasks (ms)=93361\n",
    "\t\tTotal time spent by all maps in occupied slots (ms)=186722\n",
    "\t\tTotal time spent by all reduce tasks (ms)=39748\n",
    "\t\tTotal time spent by all reduces in occupied slots (ms)=158992\n",
    "\t\tTotal vcore-milliseconds taken by all map tasks=93361\n",
    "\t\tTotal vcore-milliseconds taken by all reduce tasks=39748\n",
    "\tMap-Reduce Framework\n",
    "\t\tCPU time spent (ms)=136610\n",
    "\t\tCombine input records=0\n",
    "\t\tCombine output records=0\n",
    "\t\tFailed Shuffles=0\n",
    "\t\tGC time elapsed (ms)=584\n",
    "\t\tInput split bytes=262\n",
    "\t\tMap input records=10000000\n",
    "\t\tMap output bytes=151854186\n",
    "\t\tMap output materialized bytes=171854198\n",
    "\t\tMap output records=10000000\n",
    "\t\tMerged Map outputs=2\n",
    "\t\tPhysical memory (bytes) snapshot=3580809216\n",
    "\t\tReduce input groups=25\n",
    "\t\tReduce input records=10000000\n",
    "\t\tReduce output records=25\n",
    "\t\tReduce shuffle bytes=171854198\n",
    "\t\tShuffled Maps =2\n",
    "\t\tSpilled Records=20000000\n",
    "\t\tTotal committed heap usage (bytes)=3832545280\n",
    "\t\tVirtual memory (bytes) snapshot=13185441792\n",
    "\tShuffle Errors\n",
    "\t\tBAD_ID=0\n",
    "\t\tCONNECTION=0\n",
    "\t\tIO_ERROR=0\n",
    "\t\tWRONG_LENGTH=0\n",
    "\t\tWRONG_MAP=0\n",
    "\t\tWRONG_REDUCE=0\n",
    "Running step 2 of 2...\n",
    "  packageJobJar: [] [/usr/hdp/2.6.3.0-235/hadoop-mapreduce/hadoop-streaming-2.7.3.2.6.3.0-235.jar] /tmp/streamjob7171557325658635531.jar tmpDir=null\n",
    "  Connecting to ResourceManager at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:8050\n",
    "  Connecting to Application History server at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:10200\n",
    "  Connecting to ResourceManager at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:8050\n",
    "  Connecting to Application History server at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:10200\n",
    "  Created HDFS_DELEGATION_TOKEN token 135027 for mandyho on 10.164.5.158:8020\n",
    "  Got dt for hdfs://fladoop-nn02.arc-ts.umich.edu:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 10.164.5.158:8020, Ident: (HDFS_DELEGATION_TOKEN token 135027 for mandyho)\n",
    "  Total input paths to process : 1\n",
    "  number of splits:2\n",
    "  Submitting tokens for job: job_1547074859606_12271\n",
    "  Kind: HDFS_DELEGATION_TOKEN, Service: 10.164.5.158:8020, Ident: (HDFS_DELEGATION_TOKEN token 135027 for mandyho)\n",
    "  Timeline service address: http://fladoop-rm01.arc-ts.umich.edu:8188/ws/v1/timeline/\n",
    "  Submitted application application_1547074859606_12271\n",
    "  The url to track the job: http://fladoop-rm01.arc-ts.umich.edu:8088/proxy/application_1547074859606_12271/\n",
    "  Running job: job_1547074859606_12271\n",
    "  Job job_1547074859606_12271 running in uber mode : false\n",
    "   map 0% reduce 0%\n",
    "   map 100% reduce 0%\n",
    "   map 100% reduce 100%\n",
    "  Job job_1547074859606_12271 completed successfully\n",
    "  Output directory: hdfs:///user/mandyho/tmp/mrjob/mr_summary_stats.mandyho.20190403.233005.326941/output\n",
    "Counters: 50\n",
    "\tFile Input Format Counters \n",
    "\t\tBytes Read=2079\n",
    "\tFile Output Format Counters \n",
    "\t\tBytes Written=1197\n",
    "\tFile System Counters\n",
    "\t\tFILE: Number of bytes read=1442\n",
    "\t\tFILE: Number of bytes written=486525\n",
    "\t\tFILE: Number of large read operations=0\n",
    "\t\tFILE: Number of read operations=0\n",
    "\t\tFILE: Number of write operations=0\n",
    "\t\tHDFS: Number of bytes read=2465\n",
    "\t\tHDFS: Number of bytes written=1197\n",
    "\t\tHDFS: Number of large read operations=0\n",
    "\t\tHDFS: Number of read operations=9\n",
    "\t\tHDFS: Number of write operations=2\n",
    "\tJob Counters \n",
    "\t\tData-local map tasks=1\n",
    "\t\tLaunched map tasks=2\n",
    "\t\tLaunched reduce tasks=1\n",
    "\t\tRack-local map tasks=1\n",
    "\t\tTotal megabyte-milliseconds taken by all map tasks=21473280\n",
    "\t\tTotal megabyte-milliseconds taken by all reduce tasks=12533760\n",
    "\t\tTotal time spent by all map tasks (ms)=10485\n",
    "\t\tTotal time spent by all maps in occupied slots (ms)=20970\n",
    "\t\tTotal time spent by all reduce tasks (ms)=3060\n",
    "\t\tTotal time spent by all reduces in occupied slots (ms)=12240\n",
    "\t\tTotal vcore-milliseconds taken by all map tasks=10485\n",
    "\t\tTotal vcore-milliseconds taken by all reduce tasks=3060\n",
    "\tMap-Reduce Framework\n",
    "\t\tCPU time spent (ms)=3520\n",
    "\t\tCombine input records=0\n",
    "\t\tCombine output records=0\n",
    "\t\tFailed Shuffles=0\n",
    "\t\tGC time elapsed (ms)=141\n",
    "\t\tInput split bytes=386\n",
    "\t\tMap input records=25\n",
    "\t\tMap output bytes=1386\n",
    "\t\tMap output materialized bytes=1448\n",
    "\t\tMap output records=25\n",
    "\t\tMerged Map outputs=2\n",
    "\t\tPhysical memory (bytes) snapshot=2348179456\n",
    "\t\tReduce input groups=25\n",
    "\t\tReduce input records=25\n",
    "\t\tReduce output records=25\n",
    "\t\tReduce shuffle bytes=1448\n",
    "\t\tShuffled Maps =2\n",
    "\t\tSpilled Records=50\n",
    "\t\tTotal committed heap usage (bytes)=3269984256\n",
    "\t\tVirtual memory (bytes) snapshot=13206601728\n",
    "\tShuffle Errors\n",
    "\t\tBAD_ID=0\n",
    "\t\tCONNECTION=0\n",
    "\t\tIO_ERROR=0\n",
    "\t\tWRONG_LENGTH=0\n",
    "\t\tWRONG_MAP=0\n",
    "\t\tWRONG_REDUCE=0\n",
    "job output is in hdfs:///user/mandyho/tmp/mrjob/mr_summary_stats.mandyho.20190403.233005.326941/output\n",
    "Streaming final output from hdfs:///user/mandyho/tmp/mrjob/mr_summary_stats.mandyho.20190403.233005.326941/output...\n",
    "Removing HDFS temp directory hdfs:///user/mandyho/tmp/mrjob/mr_summary_stats.mandyho.20190403.233005.326941...\n",
    "Removing temp directory /tmp/mr_summary_stats.mandyho.20190403.233005.326941..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of __summary_large.txt__: \n",
    "```\n",
    "[mandyho@flux-hadoop-login2 hadoop]$ cat summary_large.txt\n",
    "0\t[862338.0,9.8723876989,88876649.9762566537]\n",
    "1\t[452810.0,-18.5601023777,93247482.7903822213]\n",
    "10\t[17310.0,98.4633204592,108084209.9447235465]\n",
    "11\t[897044.0,-9.164971808,83932099.4666945338]\n",
    "12\t[222066.0,-5.5062780164,80631434.9451120943]\n",
    "13\t[158627.0,44.1673229575,102056021.735591501]\n",
    "14\t[873568.0,20.4287172296,102647242.9599751383]\n",
    "15\t[17016.0,144.5863449707,78999640.0529580861]\n",
    "16\t[678390.0,17.0399901669,83348553.4643739313]\n",
    "17\t[145306.0,-3.2899699519,69866385.3784090281]\n",
    "18\t[134370.0,-14.5280964438,105645041.2298437655]\n",
    "19\t[229768.0,-3.3207148817,91850219.0803911239]\n",
    "2\t[105548.0,-15.2362230833,83553366.6341636181]\n",
    "20\t[676289.0,0.3219578656,102028374.4676386863]\n",
    "21\t[1146955.0,28.0316962742,65361314.7443429008]\n",
    "22\t[490487.0,6.2740169363,75418085.9576252997]\n",
    "23\t[223434.0,-2.9732090622,97484417.2359191328]\n",
    "24\t[112730.0,71.0843919881,103876466.2121580988]\n",
    "3\t[358093.0,0.6398833915,109463481.4812636077]\n",
    "4\t[137728.0,-21.6628919329,76603243.7971047461]\n",
    "5\t[223385.0,24.3867215747,127109022.55292283]\n",
    "6\t[1081245.0,15.9633708407,88374442.4970653802]\n",
    "7\t[341522.0,-41.021803702,117405452.4690739661]\n",
    "8\t[300539.0,25.9783215635,87148464.7218444496]\n",
    "9\t[113432.0,12.3038561143,104967969.1741923541]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use matplotlib and the results in summary_large.txt to create a plot displaying 95% confidence intervals for the sample means of the populations given by the class labels in file \n",
    "            hdfs:///var/stats507w19/populations_large.txt \n",
    "   * You will probably want to make a boxplot for this, but feel free to get creative if you think you have a better way to display the information. \n",
    "   * Make sure your plot has a sensible title and axis labels. \n",
    "   * Save your plot as a pdf called __populations.pdf__ and include it in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import scipy.stats \n",
    "import numpy as np\n",
    "# find digit\n",
    "regex = re.compile(r\"[\\d.-]+\") \n",
    "file = \"summary_large.txt\"\n",
    "\n",
    "# extract label, sample_size, mean, variance\n",
    "label = []\n",
    "n = []\n",
    "mean = []\n",
    "variance = []\n",
    "with open(file, \"r\") as f:\n",
    "    for l in f.readlines():\n",
    "        result = [word for word in regex.findall(l)]\n",
    "        label.append(int(float(result[0])))\n",
    "        n.append(int(float(result[1])))\n",
    "        mean.append(float(result[2]))\n",
    "        variance.append(float(result[3]))\n",
    "degree_of_freedom = [x-1 for x in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '4567']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check regex\n",
    "l = '1jioj4567'\n",
    "regex.findall(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.figure()\n",
    "plt.errorbar(label, mean, \n",
    "             yerr=1.96*np.sqrt(variance)/np.sqrt(n), fmt='o')\n",
    "plt.title(\"The 95% confidence intervals for the sample means of the populations\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Mean\")\n",
    "g.savefig('populations.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 Graph Processing: Counting Triangles with PySpark (6 points)\n",
    "A classic task in graph processing is called “triangle counting”. If you have never heard of graphs, that’s okay! It suffices to know that a graph is a set of nodes (also called vertices), pairs of which are joined by edges (see https://en.wikipedia.org/wiki/Graph_theory for more). \n",
    "* A triangle in graph theory is a set of three nodes, say {a, b, c}, such that all three nodes are joined by edges. \n",
    "* Triangle counting is closely related to a fundamental task for social media companies, who may wish to suggest new “friends” to users based on their existing social network. \n",
    "* In this problem, you’ll implement triangle counting in the MapReduce framework using PySpark. \n",
    "* We should note that in practice, the MapReduce framework is rather poorly-suited to the problem of counting triangles, but it’s a good problem to get you practice with the framework, so we’ll leave that be.\n",
    "\n",
    "\n",
    "* The input for this problem will be a collection of files representing users’ friend lists in a social network. Each user in the network is assigned a numeric ID, and that user’s friend list is contained in a file called __n.txt__, where n is the user’s ID. Each such file contains a single space-separated line, of the form\n",
    "                            n  f1 f2 ... fK\n",
    "where n is the node and f1,f2,...,fK are the IDs of the friends of n. So, if node 1 is friends with nodes 2,5 and 6, there will be a file __1.txt__, containing only the line 1 2 5 6. If node 10 has no friends, then there will be a file __10.txt__, containing only the line 10, or perhaps no file at all. \n",
    "* Note that just because an ID appears in a friend list, that doesn’t necessarily mean that there will be a file listing that user’s friends, but you may assume   \n",
    "__(1) symmetry__: if 100 is a friend of 200, then 200 is a friend of 100.   \n",
    "__(2) no duplication__: each friend appears in a given friend list at most once (i.e., every file will contain a given number at most once).  \n",
    "\n",
    "\n",
    "* Once again, before you dive in and write a bunch of code, sit down and think about the problem. What is the right “fundamental unit” of the problem? What should your keys and values look like? \n",
    "* Hint: the simplest solution to this problem involves multiple steps, involving a standard map-reduce pattern and a subsequent filtering operation. \n",
    "* As usual, overly complicated solutions will not receive full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Write a PySpark job that takes the described input and produces a list of all the triangles in the network, one per line. \n",
    "   * Each triangle should be listed as a space-separated line node1 node2 node3, with the entries sorted numerically in ascending order. \n",
    "   * So, if nodes 2, 5 and 15 form a triangle, the output should include the triple (2,5,15), but not (2,15,5), (15,2,5), etc. \n",
    "   * Save your script in a file called __ps_fof.py__ and include it in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ps_fof.py__:  \n",
    "\n",
    "```python\n",
    "# -*- coding: utf-8 -*-\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import sys\n",
    "from itertools import combinations\n",
    "\n",
    "if(len(sys.argv) != 3):\n",
    "    print('Usage' + sys.argv[0] + ' <in> <out>')\n",
    "    sys.exit(1)\n",
    "\n",
    "# Input file, output file\n",
    "inputLocation = sys.argv[1]\n",
    "outputLocation = sys.argv[2]\n",
    "\n",
    "# Set up spark\n",
    "conf = SparkConf().setAppName(\"CountTriangle\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# Reads in the entire directory.\n",
    "data = sc.textFile(inputLocation)\n",
    "\n",
    "'''\n",
    "Map:\n",
    "Create function map_combination that gets all combination from mutual list (pick any two)\n",
    "Key: 3-tuple (triangle) \n",
    "Value: 1 (count as once)\n",
    "Return all the combination\n",
    "Then Map all the data into key-value pairs, using flatMap\n",
    "\n",
    "Reduce:\n",
    "Sum up how many times the combinations appear (sum values by keys), using reduceByKey \n",
    "Filter for the ones more than 2 (to form triangle, need at least 2)\n",
    "'''\n",
    "# MAP\n",
    "data = data.map(lambda l: l.split())\n",
    "\n",
    "def friend_combination(data):\n",
    "    # create total combination: set combination as key, set value to 1\n",
    "    comb = []\n",
    "    N = int(data[0])\n",
    "    Fn = [int(x) for x in data[1:]] \n",
    "    tot_comb = combinations(Fn, 2)\n",
    "    for t in tot_comb:\n",
    "        each_comb = [N, t[0], t[1]]\n",
    "        comb.append((tuple(sorted(each_comb)), 1))\n",
    "    return comb\n",
    "\n",
    "map_all = data.flatMap(friend_combination)\n",
    "\n",
    "# REDUCE: count values by key, filter >= 2\n",
    "reduce_filter = map_all.reduceByKey(lambda a,b: a+b).filter(lambda a: a[1] >= 2).keys().sortBy(lambda a: a)\n",
    "# only want keys in the output (key is the combination, value is the count), sort by ascending order\n",
    "\n",
    "# formatting\n",
    "triangle = reduce_filter.map(lambda s: str(s[0]) + \" \" + str(s[1]) + \" \" + str(s[2]))\n",
    "\n",
    "# OUTPUT\n",
    "triangle.saveAsTextFile(outputLocation)\n",
    "sc.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Test your script on the set of 5 simple files in the HDFS directory\n",
    "                          hdfs:///var/stats507w19/fof/friends.simple\n",
    "which is small enough that you should be able to work out by hand what the correct\n",
    "output is. \n",
    "   * How many triangles are there? 6 triangles\n",
    "   * List them in a file called __small_triangle_list.txt__ and include it in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line on Fladoop:  \n",
    "`spark-submit --master yarn --queue stats507w19 ps_fof.py /var/stats507w19/fof/friends.simple friend_simple`  \n",
    "`hdfs dfs -ls friend_simple/`  \n",
    "`hdfs dfs -cat friend_simple/part-*`  \n",
    "`hdfs dfs -cat friend_simple/part-* > small_triangle_list.txt`  \n",
    "Download file to local machine:  \n",
    "`scp mandyho@flux-hadoop-login.arc-ts.umich.edu:~/hadoop/small_triangle_list.txt .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of __small_triangle_list.txt__:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[mandyho@flux-hadoop-login2 hadoop]$ cat small_triangle_list.txt\n",
    "100 200 217\n",
    "100 200 300\n",
    "100 200 400\n",
    "100 300 400\n",
    "200 300 400\n",
    "300 400 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Once you are confident that your script is correct, run it on the larger data set, stored on HDFS at   \n",
    "                        hdfs:/var/stats507w19/fof/friends1000\n",
    "   * Save the list of triangles to a file called __big_triangle_list.tx__t, and include it in your submission. \n",
    "   * Don’t forget to include in your notebook file a copy-paste of the commands you used to launch your job along with their outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command line on Fladoop:  \n",
    "`spark-submit --master yarn --queue stats507w19 ps_fof.py /var/stats507w19/fof/friends1000 friend_large`  \n",
    "`hdfs dfs -ls friend_large/`   \n",
    "`hdfs dfs -cat friend_large/part-*`  \n",
    "`hdfs dfs -cat friend_large/part-* > big_triangle_list.txt`   \n",
    "Download file to local machine:  \n",
    "`scp mandyho@flux-hadoop-login.arc-ts.umich.edu:~/hadoop/big_triangle_list.txt .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial output of __big_triangle_list.txt__:\n",
    "```\n",
    "[mandyho@flux-hadoop-login2 hadoop]$ head -n10 big_triangle_list.txt\n",
    "0 7 74\n",
    "0 7 193\n",
    "0 7 283\n",
    "0 7 332\n",
    "0 7 483\n",
    "0 7 602\n",
    "0 7 692\n",
    "0 11 42\n",
    "0 11 82\n",
    "0 11 127\n",
    "[mandyho@flux-hadoop-login2 hadoop]$ tail -n10 big_triangle_list.txt\n",
    "948 983 996\n",
    "952 963 993\n",
    "954 957 985\n",
    "955 974 978\n",
    "955 978 998\n",
    "958 964 972\n",
    "958 966 972\n",
    "965 973 991\n",
    "965 991 999\n",
    "970 971 983\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are total 144120 triangles:\n",
    "```\n",
    "[mandyho@flux-hadoop-login2 hadoop]$ wc -l big_triangle_list.txt\n",
    "144120 big_triangle_list.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output of Fladoop shell:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[mandyho@flux-hadoop-login2 hadoop]$ spark-submit --master yarn --queue stats507w19 ps_fof.py /var/stats507w19/fof/friends1000 friend_large\n",
    "SPARK_MAJOR_VERSION is set to 2, using Spark2\n",
    "19/04/04 22:41:35 INFO SparkContext: Running Spark version 2.2.0.2.6.3.0-235\n",
    "19/04/04 22:41:35 INFO SparkContext: Submitted application: CountTriangle\n",
    "19/04/04 22:41:35 INFO SecurityManager: Changing view acls to: mandyho\n",
    "19/04/04 22:41:35 INFO SecurityManager: Changing modify acls to: mandyho\n",
    "19/04/04 22:41:35 INFO SecurityManager: Changing view acls groups to: \n",
    "19/04/04 22:41:35 INFO SecurityManager: Changing modify acls groups to: \n",
    "19/04/04 22:41:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(mandyho); groups with view permissions: Set(); users  with modify permissions: Set(mandyho); groups with modify permissions: Set()\n",
    "19/04/04 22:41:36 INFO Utils: Successfully started service 'sparkDriver' on port 41486.\n",
    "19/04/04 22:41:36 INFO SparkEnv: Registering MapOutputTracker\n",
    "19/04/04 22:41:36 INFO SparkEnv: Registering BlockManagerMaster\n",
    "19/04/04 22:41:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
    "19/04/04 22:41:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
    "19/04/04 22:41:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-24723307-8dea-42a4-869b-cf039e142cb7\n",
    "19/04/04 22:41:36 INFO MemoryStore: MemoryStore started with capacity 366.3 MB\n",
    "19/04/04 22:41:36 INFO SparkEnv: Registering OutputCommitCoordinator\n",
    "19/04/04 22:41:36 INFO log: Logging initialized @4304ms\n",
    "19/04/04 22:41:36 INFO Server: jetty-9.3.z-SNAPSHOT\n",
    "19/04/04 22:41:36 INFO Server: Started @4411ms\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
    "19/04/04 22:41:36 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
    "19/04/04 22:41:36 INFO AbstractConnector: Started ServerConnector@79bea9d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4048}\n",
    "19/04/04 22:41:36 INFO Utils: Successfully started service 'SparkUI' on port 4048.\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@125f44c6{/jobs,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6c2628ff{/jobs/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@23781411{/jobs/job,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@ed737d8{/jobs/job/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@306b0a31{/stages,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@62585a1e{/stages/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@47c11f6{/stages/stage,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3ac376f6{/stages/stage/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5b78cb00{/stages/pool,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@57dbe46{/stages/pool/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@67b4196e{/storage,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6bd8eb44{/storage/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1933c0c0{/storage/rdd,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4909cc14{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4e5837e3{/environment,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@108126f3{/environment/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@42e23f{/executors,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@776792c4{/executors/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3e8f39a9{/executors/threadDump,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5fed9a43{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6afc1c31{/static,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7e40f167{/,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2d12ca5a{/api,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@55b865c2{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@34f7508b{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:36 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://141.211.22.220:4048\n",
    "19/04/04 22:41:37 INFO RMProxy: Connecting to ResourceManager at fladoop-rm01.arc-ts.umich.edu/10.164.5.157:8050\n",
    "19/04/04 22:41:38 INFO Client: Requesting a new application from cluster with 11 NodeManagers\n",
    "19/04/04 22:41:38 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (40192 MB per container)\n",
    "19/04/04 22:41:38 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\n",
    "19/04/04 22:41:38 INFO Client: Setting up container launch context for our AM\n",
    "19/04/04 22:41:38 INFO Client: Setting up the launch environment for our AM container\n",
    "19/04/04 22:41:38 INFO Client: Preparing resources for our AM container\n",
    "19/04/04 22:41:38 INFO HadoopFSCredentialProvider: getting token for: hdfs://fladoop-nn02.arc-ts.umich.edu:8020/user/mandyho\n",
    "19/04/04 22:41:38 INFO DFSClient: Created HDFS_DELEGATION_TOKEN token 137921 for mandyho on 10.164.5.158:8020\n",
    "19/04/04 22:41:40 INFO metastore: Trying to connect to metastore with URI thrift://fladoop-rm01.arc-ts.umich.edu:9083\n",
    "19/04/04 22:41:40 INFO metastore: Connected to metastore.\n",
    "19/04/04 22:41:40 INFO HiveCredentialProvider: Get Token from hive metastore: Kind: HIVE_DELEGATION_TOKEN, Service: , Ident: 00 11 6d 61 6e 64 79 68 6f 40 55 4d 49 43 48 2e 45 44 55 04 68 69 76 65 00 8a 01 69 eb 5f 88 9d 8a 01 6a 0f 6c 0c 9d 8e 03 f7 8e 01 c9\n",
    "19/04/04 22:41:40 INFO Client: Use hdfs cache file as spark.yarn.archive for HDP, hdfsCacheFile:hdfs://fladoop-nn02.arc-ts.umich.edu:8020/hdp/apps/2.6.3.0-235/spark2/spark2-hdp-yarn-archive.tar.gz\n",
    "19/04/04 22:41:40 INFO Client: Source and destination file systems are the same. Not copying hdfs://fladoop-nn02.arc-ts.umich.edu:8020/hdp/apps/2.6.3.0-235/spark2/spark2-hdp-yarn-archive.tar.gz\n",
    "19/04/04 22:41:40 INFO Client: Uploading resource file:/usr/hdp/current/spark2-client/python/lib/pyspark.zip -> hdfs://fladoop-nn02.arc-ts.umich.edu:8020/user/mandyho/.sparkStaging/application_1547074859606_14877/pyspark.zip\n",
    "19/04/04 22:41:41 INFO Client: Uploading resource file:/usr/hdp/current/spark2-client/python/lib/py4j-0.10.4-src.zip -> hdfs://fladoop-nn02.arc-ts.umich.edu:8020/user/mandyho/.sparkStaging/application_1547074859606_14877/py4j-0.10.4-src.zip\n",
    "19/04/04 22:41:41 INFO Client: Uploading resource file:/tmp/spark-7dc861e5-b6a8-4025-b091-e6ffeca903c0/__spark_conf__3096568943266744879.zip -> hdfs://fladoop-nn02.arc-ts.umich.edu:8020/user/mandyho/.sparkStaging/application_1547074859606_14877/__spark_conf__.zip\n",
    "19/04/04 22:41:41 INFO SecurityManager: Changing view acls to: mandyho\n",
    "19/04/04 22:41:41 INFO SecurityManager: Changing modify acls to: mandyho\n",
    "19/04/04 22:41:41 INFO SecurityManager: Changing view acls groups to: \n",
    "19/04/04 22:41:41 INFO SecurityManager: Changing modify acls groups to: \n",
    "19/04/04 22:41:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(mandyho); groups with view permissions: Set(); users  with modify permissions: Set(mandyho); groups with modify permissions: Set()\n",
    "19/04/04 22:41:41 INFO Client: Submitting application application_1547074859606_14877 to ResourceManager\n",
    "19/04/04 22:41:41 INFO YarnClientImpl: Submitted application application_1547074859606_14877\n",
    "19/04/04 22:41:41 INFO SchedulerExtensionServices: Starting Yarn extension services with app application_1547074859606_14877 and attemptId None\n",
    "19/04/04 22:41:42 INFO Client: Application report for application_1547074859606_14877 (state: ACCEPTED)\n",
    "19/04/04 22:41:42 INFO Client: \n",
    "\t client token: Token { kind: YARN_CLIENT_TOKEN, service:  }\n",
    "\t diagnostics: AM container is launched, waiting for AM container to Register with RM\n",
    "\t ApplicationMaster host: N/A\n",
    "\t ApplicationMaster RPC port: -1\n",
    "\t queue: stats507w19\n",
    "\t start time: 1554432101530\n",
    "\t final status: UNDEFINED\n",
    "\t tracking URL: http://fladoop-rm01.arc-ts.umich.edu:8088/proxy/application_1547074859606_14877/\n",
    "\t user: mandyho\n",
    "19/04/04 22:41:43 INFO Client: Application report for application_1547074859606_14877 (state: ACCEPTED)\n",
    "19/04/04 22:41:44 INFO Client: Application report for application_1547074859606_14877 (state: ACCEPTED)\n",
    "19/04/04 22:41:45 INFO Client: Application report for application_1547074859606_14877 (state: ACCEPTED)\n",
    "19/04/04 22:41:46 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> fladoop-rm01.arc-ts.umich.edu, PROXY_URI_BASES -> http://fladoop-rm01.arc-ts.umich.edu:8088/proxy/application_1547074859606_14877), /proxy/application_1547074859606_14877\n",
    "19/04/04 22:41:46 INFO JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\n",
    "19/04/04 22:41:46 INFO Client: Application report for application_1547074859606_14877 (state: RUNNING)\n",
    "19/04/04 22:41:46 INFO Client: \n",
    "\t client token: Token { kind: YARN_CLIENT_TOKEN, service:  }\n",
    "\t diagnostics: N/A\n",
    "\t ApplicationMaster host: 10.164.1.144\n",
    "\t ApplicationMaster RPC port: 0\n",
    "\t queue: stats507w19\n",
    "\t start time: 1554432101530\n",
    "\t final status: UNDEFINED\n",
    "\t tracking URL: http://fladoop-rm01.arc-ts.umich.edu:8088/proxy/application_1547074859606_14877/\n",
    "\t user: mandyho\n",
    "19/04/04 22:41:46 INFO YarnClientSchedulerBackend: Application application_1547074859606_14877 has started running.\n",
    "19/04/04 22:41:46 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\n",
    "19/04/04 22:41:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39505.\n",
    "19/04/04 22:41:46 INFO NettyBlockTransferService: Server created on 141.211.22.220:39505\n",
    "19/04/04 22:41:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
    "19/04/04 22:41:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 141.211.22.220, 39505, None)\n",
    "19/04/04 22:41:46 INFO BlockManagerMasterEndpoint: Registering block manager 141.211.22.220:39505 with 366.3 MB RAM, BlockManagerId(driver, 141.211.22.220, 39505, None)\n",
    "19/04/04 22:41:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 141.211.22.220, 39505, None)\n",
    "19/04/04 22:41:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 141.211.22.220, 39505, None)\n",
    "19/04/04 22:41:47 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4bdd82d4{/metrics/json,null,AVAILABLE,@Spark}\n",
    "19/04/04 22:41:47 INFO EventLoggingListener: Logging events to hdfs:///spark2-history/application_1547074859606_14877\n",
    "19/04/04 22:41:52 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.5.151:45922) with ID 1\n",
    "19/04/04 22:41:52 INFO BlockManagerMasterEndpoint: Registering block manager fladoop-dn0009.arc-ts.umich.edu:35346 with 366.3 MB RAM, BlockManagerId(1, fladoop-dn0009.arc-ts.umich.edu, 35346, None)\n",
    "19/04/04 22:41:52 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.5.151 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:337)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:326)\n",
    "\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n",
    "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n",
    "\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n",
    "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOffers(TaskSchedulerImpl.scala:326)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$makeOffers(CoarseGrainedSchedulerBackend.scala:237)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1.applyOrElse(CoarseGrainedSchedulerBackend.scala:200)\n",
    "\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
    "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:748)\n",
    "19/04/04 22:41:52 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.5.151 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:337)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:326)\n",
    "\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n",
    "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n",
    "\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n",
    "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOffers(TaskSchedulerImpl.scala:326)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$makeOffers(CoarseGrainedSchedulerBackend.scala:237)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1.applyOrElse(CoarseGrainedSchedulerBackend.scala:137)\n",
    "\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
    "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:748)\n",
    "19/04/04 22:41:52 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.164.1.140:60946) with ID 2\n",
    "19/04/04 22:41:52 INFO BlockManagerMasterEndpoint: Registering block manager fladoop-dn0001.arc-ts.umich.edu:35734 with 366.3 MB RAM, BlockManagerId(2, fladoop-dn0001.arc-ts.umich.edu, 35734, None)\n",
    "19/04/04 22:41:52 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.1.140 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:337)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:326)\n",
    "\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n",
    "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n",
    "\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n",
    "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOffers(TaskSchedulerImpl.scala:326)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$makeOffers(CoarseGrainedSchedulerBackend.scala:237)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1.applyOrElse(CoarseGrainedSchedulerBackend.scala:200)\n",
    "\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
    "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:748)\n",
    "19/04/04 22:41:52 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.5.151 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:337)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:326)\n",
    "\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n",
    "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n",
    "\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n",
    "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOffers(TaskSchedulerImpl.scala:326)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$makeOffers(CoarseGrainedSchedulerBackend.scala:237)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receiveAndReply$1.applyOrElse(CoarseGrainedSchedulerBackend.scala:200)\n",
    "\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:105)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
    "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:748)\n",
    "19/04/04 22:41:52 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8\n",
    "19/04/04 22:41:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 360.2 KB, free 365.9 MB)\n",
    "19/04/04 22:41:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.0 KB, free 365.9 MB)\n",
    "19/04/04 22:41:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 141.211.22.220:39505 (size: 33.0 KB, free: 366.3 MB)\n",
    "19/04/04 22:41:53 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0\n",
    "19/04/04 22:41:53 INFO FileInputFormat: Total input paths to process : 1000\n",
    "19/04/04 22:41:53 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.1.140 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:337)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:326)\n",
    "\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n",
    "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n",
    "\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n",
    "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOffers(TaskSchedulerImpl.scala:326)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$makeOffers(CoarseGrainedSchedulerBackend.scala:237)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1.applyOrElse(CoarseGrainedSchedulerBackend.scala:137)\n",
    "\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
    "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:748)\n",
    "19/04/04 22:41:54 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.5.151 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:337)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$resourceOffers$1.apply(TaskSchedulerImpl.scala:326)\n",
    "\tat scala.collection.Iterator$class.foreach(Iterator.scala:893)\n",
    "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1336)\n",
    "\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n",
    "\tat scala.collection.AbstractIterable.foreach(Iterable.scala:54)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.resourceOffers(TaskSchedulerImpl.scala:326)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint.org$apache$spark$scheduler$cluster$CoarseGrainedSchedulerBackend$DriverEndpoint$$makeOffers(CoarseGrainedSchedulerBackend.scala:237)\n",
    "\tat org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend$DriverEndpoint$$anonfun$receive$1.applyOrElse(CoarseGrainedSchedulerBackend.scala:137)\n",
    "\tat org.apache.spark.rpc.netty.Inbox$$anonfun$process$1.apply$mcV$sp(Inbox.scala:117)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:205)\n",
    "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:101)\n",
    "\tat org.apache.spark.rpc.netty.Dispatcher$MessageLoop.run(Dispatcher.scala:216)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
    "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
    "\tat java.lang.Thread.run(Thread.java:748)\n",
    "19/04/04 22:41:54 INFO SparkContext: Starting job: sortBy at /home/mandyho/hadoop/ps_fof.py:50\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Registering RDD 3 (reduceByKey at /home/mandyho/hadoop/ps_fof.py:50)\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Got job 0 (sortBy at /home/mandyho/hadoop/ps_fof.py:50) with 1000 output partitions\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Final stage: ResultStage 1 (sortBy at /home/mandyho/hadoop/ps_fof.py:50)\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/mandyho/hadoop/ps_fof.py:50), which has no missing parents\n",
    "19/04/04 22:41:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.9 KB, free 365.9 MB)\n",
    "19/04/04 22:41:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.5 KB, free 365.9 MB)\n",
    "19/04/04 22:41:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 141.211.22.220:39505 (size: 6.5 KB, free: 366.3 MB)\n",
    "19/04/04 22:41:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006\n",
    "19/04/04 22:41:54 INFO DAGScheduler: Submitting 1000 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/mandyho/hadoop/ps_fof.py:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
    "19/04/04 22:41:54 INFO YarnScheduler: Adding task set 0.0 with 1000 tasks\n",
    "19/04/04 22:41:54 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.1.141 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1.apply(TaskSetManager.scala:225)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1.apply(TaskSetManager.scala:206)\n",
    "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
    "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager.addPendingTask(TaskSetManager.scala:206)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$1.apply$mcVI$sp(TaskSetManager.scala:178)\n",
    "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager.<init>(TaskSetManager.scala:177)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.createTaskSetManager(TaskSchedulerImpl.scala:229)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.submitTasks(TaskSchedulerImpl.scala:193)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1055)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:930)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:933)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:932)\n",
    "\tat scala.collection.immutable.List.foreach(List.scala:381)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:932)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:874)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1695)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n",
    "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
    "19/04/04 22:41:54 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.1.144 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1.apply(TaskSetManager.scala:225)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1.apply(TaskSetManager.scala:206)\n",
    "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
    "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager.addPendingTask(TaskSetManager.scala:206)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$1.apply$mcVI$sp(TaskSetManager.scala:178)\n",
    "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager.<init>(TaskSetManager.scala:177)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.createTaskSetManager(TaskSchedulerImpl.scala:229)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.submitTasks(TaskSchedulerImpl.scala:193)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1055)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:930)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:933)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:932)\n",
    "\tat scala.collection.immutable.List.foreach(List.scala:381)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:932)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:874)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1695)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n",
    "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
    "19/04/04 22:41:54 WARN ScriptBasedMapping: Exception running /etc/hadoop/conf/topology_script.py 10.164.1.143 \n",
    "ExitCodeException exitCode=1:   File \"/etc/hadoop/conf/topology_script.py\", line 63\n",
    "    print rack\n",
    "             ^\n",
    "SyntaxError: Missing parentheses in call to 'print'. Did you mean print(int rack)?\n",
    "\n",
    "\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:944)\n",
    "\tat org.apache.hadoop.util.Shell.run(Shell.java:848)\n",
    "\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1142)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.runResolveCommand(ScriptBasedMapping.java:251)\n",
    "\tat org.apache.hadoop.net.ScriptBasedMapping$RawScriptBasedMapping.resolve(ScriptBasedMapping.java:188)\n",
    "\tat org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.coreResolve(RackResolver.java:101)\n",
    "\tat org.apache.hadoop.yarn.util.RackResolver.resolve(RackResolver.java:81)\n",
    "\tat org.apache.spark.scheduler.cluster.YarnScheduler.getRackForHost(YarnScheduler.scala:37)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1.apply(TaskSetManager.scala:225)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$addPendingTask$1.apply(TaskSetManager.scala:206)\n",
    "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
    "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager.addPendingTask(TaskSetManager.scala:206)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager$$anonfun$1.apply$mcVI$sp(TaskSetManager.scala:178)\n",
    "\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n",
    "\tat org.apache.spark.scheduler.TaskSetManager.<init>(TaskSetManager.scala:177)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.createTaskSetManager(TaskSchedulerImpl.scala:229)\n",
    "\tat org.apache.spark.scheduler.TaskSchedulerImpl.submitTasks(TaskSchedulerImpl.scala:193)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.submitMissingTasks(DAGScheduler.scala:1055)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:930)\n",
    "\tat org.apache.spark.scheduler.DAGSchedu\n",
    "    ler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:933)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$submitStage$4.apply(DAGScheduler.scala:932)\n",
    "\tat scala.collection.immutable.List.foreach(List.scala:381)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$submitStage(DAGScheduler.scala:932)\n",
    "\tat org.apache.spark.scheduler.DAGScheduler.handleJobSubmitted(DAGScheduler.scala:874)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1695)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n",
    "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n",
    "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n",
    "\n",
    "\n",
    "[...]\n",
    "[omitting some output]\n",
    "[...]\n",
    "\n",
    "\n",
    "19/04/04 22:57:29 INFO AbstractConnector: Stopped Spark@79bea9d1{HTTP/1.1,[http/1.1]}{0.0.0.0:4048}\n",
    "19/04/04 22:57:29 INFO SparkUI: Stopped Spark web UI at http://141.211.22.220:4048\n",
    "19/04/04 22:57:29 INFO YarnClientSchedulerBackend: Interrupting monitor thread\n",
    "19/04/04 22:57:29 INFO YarnClientSchedulerBackend: Shutting down all executors\n",
    "19/04/04 22:57:29 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
    "19/04/04 22:57:29 INFO SchedulerExtensionServices: Stopping SchedulerExtensionServices\n",
    "(serviceOption=None,\n",
    " services=List(),\n",
    " started=false)\n",
    "19/04/04 22:57:29 INFO YarnClientSchedulerBackend: Stopped\n",
    "19/04/04 22:57:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
    "19/04/04 22:57:29 INFO MemoryStore: MemoryStore cleared\n",
    "19/04/04 22:57:29 INFO BlockManager: BlockManager stopped\n",
    "19/04/04 22:57:29 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
    "19/04/04 22:57:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
    "19/04/04 22:57:29 INFO SparkContext: Successfully stopped SparkContext\n",
    "19/04/04 22:57:30 INFO ShutdownHookManager: Shutdown hook called\n",
    "19/04/04 22:57:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7dc861e5-b6a8-4025-b091-e6ffeca903c0/pyspark-655df20c-4461-437e-8e95-570d6c14547c\n",
    "19/04/04 22:57:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-7dc861e5-b6a8-4025-b091-e6ffeca903c0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
